{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from transformers import AutoFeatureExtractor, AutoModelForObjectDetection\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"Initializing object detection model...\")\n",
    "# Load the DETR model and feature extractor\n",
    "extractor = AutoFeatureExtractor.from_pretrained(\"roupenminassian/detr-resnet-101-finetuned\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\"roupenminassian/detr-resnet-101-finetuned\")\n",
    "print(\"Model initialized!\")\n",
    "\n",
    "# COCO Class labels mapping\n",
    "COCO_LABELS = {0: 'Car', 1: 'Van', 2: 'Truck', 3: 'Bus', 4: 'Motorbike'}\n",
    "\n",
    "def map_indices_to_labels(index):\n",
    "    return COCO_LABELS.get(index, None)\n",
    "\n",
    "print(\"Setting up video capture...\")\n",
    "# Load the video for processing\n",
    "video_path = '/Users/roupenminassian/Downloads/GOPR0069.MP4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "height, width = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "# Define points for perspective transformation\n",
    "src_points = np.array([\n",
    "    [274, 720],\n",
    "    [575, 348],\n",
    "    [789, 348],\n",
    "    [1089, 720]\n",
    "], dtype=np.float32)\n",
    "\n",
    "dst_width = width\n",
    "dst_height = int(height * 0.75)  # Adjust this to control the height of the bird's-eye view\n",
    "dst_points = np.array([\n",
    "    [0, dst_height],\n",
    "    [0, 0],\n",
    "    [dst_width, 0],\n",
    "    [dst_width, dst_height]\n",
    "], dtype=np.float32)\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "# Warp the source points using the transformation matrix\n",
    "warped_src_points = cv2.perspectiveTransform(src_points.reshape(-1, 1, 2), M).reshape(-1, 2)\n",
    "\n",
    "# Calculate the pixel distance between the top and bottom points in the transformed frame\n",
    "warped_distance_pixels = np.linalg.norm(warped_src_points[0] - warped_src_points[3])\n",
    "\n",
    "# Define lane separation and x-coordinates for lanes\n",
    "line_separation = dst_width / 5  # Divided by 5 to get 4 lanes\n",
    "center_x = dst_width / 2 - 25\n",
    "x_coords = [\n",
    "    center_x - 1.5 * line_separation,\n",
    "    center_x - 0.5 * line_separation,\n",
    "    center_x + 0.5 * line_separation,\n",
    "    center_x + 1.5 * line_separation\n",
    "]\n",
    "\n",
    "def get_lane_from_centroid(cx):\n",
    "    if cx < x_coords[0]:\n",
    "        return \"Lane 1\"\n",
    "    elif cx < x_coords[1]:\n",
    "        return \"Lane 2\"\n",
    "    elif cx < x_coords[2]:\n",
    "        return \"Lane 3\"\n",
    "    elif cx < x_coords[3]:\n",
    "        return \"Lane 4\"\n",
    "    else:\n",
    "        return \"Lane 5\"\n",
    "\n",
    "def get_video_creation_date(video_path):\n",
    "    cmd = ['exiftool', '-s', '-s', '-s', '-CreateDate', video_path]\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        return result.stdout.strip()\n",
    "    else:\n",
    "        print(f\"Error executing exiftool: {result.stderr}\")\n",
    "        return None\n",
    "\n",
    "print(\"Fetching video creation date...\")\n",
    "creation_date_str = get_video_creation_date(video_path)\n",
    "creation_date = datetime.strptime(creation_date_str, '%Y:%m:%d %H:%M:%S')\n",
    "print(f\"Video creation date: {creation_date}\")\n",
    "\n",
    "all_labels = list(COCO_LABELS.values())\n",
    "all_lanes = [\"Lane 1\", \"Lane 2\", \"Lane 3\", \"Lane 4\", \"Lane 5\"]\n",
    "\n",
    "detections = []\n",
    "previous_detections = []\n",
    "conversion_factor = 1\n",
    "MAX_PERMISSIBLE_DISTANCE = 28\n",
    "REAL_WORLD_DISTANCE = 28 # in meters\n",
    "REAL_WORLD_BOX_HEIGHT = 28 # in meters\n",
    "\n",
    "# Calculate the pixel-to-meter conversion factor\n",
    "conversion_factor = REAL_WORLD_BOX_HEIGHT / warped_distance_pixels\n",
    "\n",
    "# Define the number of segments\n",
    "NUM_SEGMENTS = 10\n",
    "segment_height = dst_height / NUM_SEGMENTS\n",
    "\n",
    "# Define the pixel-to-meter ratio at the bottom and top of the image\n",
    "# You can adjust these based on your knowledge of the scene\n",
    "ratio_bottom = REAL_WORLD_DISTANCE / dst_height\n",
    "ratio_top = ratio_bottom * 0.5  # This is an example; adjust as needed\n",
    "\n",
    "# Calculate the ratio for each segment\n",
    "segment_ratios = np.linspace(ratio_bottom, ratio_top, NUM_SEGMENTS)\n",
    "\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_count = 0\n",
    "\n",
    "print(\"Starting frame processing...\")\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Video processing completed!\")\n",
    "        break\n",
    "\n",
    "    timestamp_seconds = frame_count / frame_rate\n",
    "    current_timestamp = creation_date + timedelta(seconds=timestamp_seconds)\n",
    "    print(f\"\\nProcessing frame {frame_count} at timestamp {current_timestamp}...\")\n",
    "\n",
    "    # Transform the frame to bird's-eye view\n",
    "    warped_frame = cv2.warpPerspective(frame, M, (dst_width, dst_height))\n",
    "\n",
    "    current_detections = []\n",
    "    \n",
    "    frame_rgb = cv2.cvtColor(warped_frame, cv2.COLOR_BGR2RGB)\n",
    "    inputs = extractor(images=frame_rgb, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    predicted_logits = outputs.logits.softmax(-1).detach().cpu().numpy()\n",
    "    predicted_boxes = outputs.pred_boxes[0].detach().cpu().numpy()\n",
    "\n",
    "    # Create a temporary dictionary to store the counts for this frame\n",
    "    frame_counts = {(label, lane): 0 for label in all_labels for lane in all_lanes}\n",
    "\n",
    "    for query in range(predicted_logits.shape[1]):\n",
    "        label = predicted_logits[0, query].argmax()\n",
    "        label_name = map_indices_to_labels(label)\n",
    "\n",
    "        if label_name and predicted_logits[0, query][label] > 0.6 and label_name in COCO_LABELS.values():\n",
    "            center_x = int(predicted_boxes[query, 0] * dst_width)\n",
    "            center_y = int(predicted_boxes[query, 1] * dst_height)\n",
    "            box_width = int(predicted_boxes[query, 2] * dst_width)\n",
    "            box_height = int(predicted_boxes[query, 3] * dst_height)\n",
    "\n",
    "            xmin = int(center_x - box_width / 2)\n",
    "            ymin = int(center_y - box_height / 2)\n",
    "            xmax = int(center_x + box_width / 2)\n",
    "            ymax = int(center_y + box_height / 2)\n",
    "\n",
    "            current_detections.append({\n",
    "            'label': label_name,\n",
    "            'centroid': (center_x, center_y),\n",
    "            'box': (xmin, ymin, xmax, ymax)\n",
    "            })\n",
    "\n",
    "            cv2.rectangle(warped_frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "            cv2.putText(warped_frame, f\"{label_name}: {predicted_logits[0, query][label]:.2f}\", (xmin, ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "            lane_of_object = get_lane_from_centroid(center_x)\n",
    "            print(f\"Object {label_name} at ({center_x}, {center_y}) is in: {lane_of_object}\")\n",
    "\n",
    "    # Now, calculate speeds by comparing current detections with previous detections\n",
    "    for curr_det in current_detections:\n",
    "        closest_prev_det = None\n",
    "        min_distance = float('inf')\n",
    "\n",
    "        for prev_det in previous_detections:\n",
    "            if prev_det['label'] == curr_det['label']:\n",
    "                distance = np.sqrt((curr_det['centroid'][0] - prev_det['centroid'][0])**2 + \n",
    "                                   (curr_det['centroid'][1] - prev_det['centroid'][1])**2)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    closest_prev_det = prev_det\n",
    "\n",
    "        if closest_prev_det and min_distance <= MAX_PERMISSIBLE_DISTANCE:\n",
    "            # Calculate speed in pixels/frame\n",
    "            speed_pixel_per_frame = min_distance\n",
    "\n",
    "            # Convert this to real-world speed using frame rate and the conversion factor\n",
    "            speed_m_per_s = speed_pixel_per_frame * frame_rate * conversion_factor\n",
    "            speed_km_per_h = speed_m_per_s * 3.6  # Convert m/s to km/h\n",
    "           \n",
    "            print(f\"Object {curr_det['label']} in {get_lane_from_centroid(curr_det['centroid'][0])} moved at {speed_km_per_h:.2f} km/h\")\n",
    "\n",
    "    # Update previous detections for the next iteration\n",
    "    previous_detections = current_detections\n",
    "\n",
    "    # Append the counts (including zeros) to the detections list\n",
    "    for (label, lane), count in frame_counts.items():\n",
    "        detections.append({\n",
    "            'timestamp': current_timestamp,\n",
    "            'label': label,\n",
    "            'lane': lane,\n",
    "            'count': count\n",
    "        })\n",
    "\n",
    "    for x in x_coords:\n",
    "        cv2.line(warped_frame, (int(x), 0), (int(x), dst_height), (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('Bird\\'s-Eye View with Lanes and Detected Objects', warped_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"User interrupted video processing!\")\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "print(\"Releasing video capture and closing windows...\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Converting detections to DataFrame...\")\n",
    "# Convert the list of detections to a DataFrame\n",
    "df = pd.DataFrame(detections)\n",
    "\n",
    "print(\"Aggregating data...\")\n",
    "# Aggregate by second, label, and lane to get the average number of vehicles\n",
    "aggregated_data = df.groupby(['timestamp', 'label', 'lane']).sum().reset_index()\n",
    "\n",
    "print(aggregated_data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
