{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.8.0.76)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.8.0)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.33.2)\n",
      "Requirement already satisfied: timm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.9.7)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from opencv-python) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.17.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python matplotlib transformers timm torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create Transformed Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Mouse callback function\n",
    "def select_point(event, x, y, flags, param):\n",
    "    global src_points\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(temp_frame, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow(\"Frame\", temp_frame)\n",
    "        if len(src_points) < 4:\n",
    "            src_points.append([x, y])\n",
    "\n",
    "# Load the video for processing\n",
    "video_path = '/Users/roupenminassian/Downloads/IMG_6362.MP4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "height, width = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "ret, first_frame = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    print(\"Failed to read the video\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "# Display the first frame for point selection\n",
    "cv2.namedWindow(\"Frame\")\n",
    "cv2.setMouseCallback(\"Frame\", select_point)\n",
    "temp_frame = first_frame.copy()\n",
    "src_points = []\n",
    "\n",
    "print(\"Select the four points by clicking on the frame. After selecting, press any key to continue.\")\n",
    "cv2.imshow(\"Frame\", first_frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Ensure that exactly 4 points were selected\n",
    "if len(src_points) != 4:\n",
    "    print(\"You must select exactly 4 points!\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "src_points = np.array(src_points, dtype=np.float32)\n",
    "\n",
    "dst_width = width\n",
    "dst_height = int(height * 0.75)\n",
    "dst_points = np.array([\n",
    "    [0, dst_height],\n",
    "    [0, 0],\n",
    "    [dst_width, 0],\n",
    "    [dst_width, dst_height]\n",
    "], dtype=np.float32)\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "# Folder to save the transformed frames\n",
    "output_folder = '/Users/roupenminassian/Downloads/Train_6362/'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "print(\"Starting frame processing...\")\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Video processing completed!\")\n",
    "        break\n",
    "\n",
    "    # Transform the frame to bird's-eye view\n",
    "    warped_frame = cv2.warpPerspective(frame, M, (dst_width, dst_height))\n",
    "\n",
    "    # Save the transformed frame\n",
    "    output_path = os.path.join(output_folder, f\"frame_{frame_count}.jpg\")\n",
    "    cv2.imwrite(output_path, warped_frame)\n",
    "\n",
    "    print(f\"Saved transformed frame {frame_count} to {output_path}\")\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "print(\"Releasing video capture...\")\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths to the source folders and destination folder\n",
    "source_folders = [\n",
    "    '/Users/roupenminassian/Downloads/TRAIN_0078',\n",
    "    '/Users/roupenminassian/Downloads/TRAIN_6352',\n",
    "    '/Users/roupenminassian/Downloads/TRAIN_6353',\n",
    "    '/Users/roupenminassian/Downloads/TRAIN_6362',\n",
    "    '/Users/roupenminassian/Downloads/Train Folder'\n",
    "]\n",
    "destination_folder = '/Users/roupenminassian/Downloads/Training File'\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Counter to keep track of file naming\n",
    "counter = 1\n",
    "\n",
    "for folder in source_folders:\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        # Ensure we're processing a file and not a sub-directory\n",
    "        if os.path.isfile(os.path.join(folder, filename)):\n",
    "            # Create the new filename based on the counter\n",
    "            new_filename = f\"frame_{counter:04}.jpg\"  # This will format the counter as 001, 002, etc.\n",
    "            # Move and rename the file to the destination folder\n",
    "            shutil.move(os.path.join(folder, filename), os.path.join(destination_folder, new_filename))\n",
    "            # Increment the counter\n",
    "            counter += 1\n",
    "\n",
    "print(\"Files merged and renamed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "\n",
    "def parse_annotation(annotation_path, image_width, image_height):\n",
    "    objects = {'id': [], 'area': [], 'bbox': [], 'category': []}\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for idx, line in enumerate(lines):\n",
    "            tokens = line.strip().split(' ')\n",
    "            category = int(tokens[0])\n",
    "            center_x, center_y, width, height = map(float, tokens[1:])\n",
    "            center_x *= image_width\n",
    "            center_y *= image_height\n",
    "            width *= image_width\n",
    "            height *= image_height\n",
    "            \n",
    "            # Compute bounding box coordinates\n",
    "            x1 = center_x - (width / 2)\n",
    "            y1 = center_y - (height / 2)\n",
    "            x2 = x1 + width\n",
    "            y2 = y1 + height\n",
    "            \n",
    "            # Clip the coordinates to image boundaries\n",
    "            x1 = max(0, x1)\n",
    "            y1 = max(0, y1)\n",
    "            x2 = min(image_width, x2)\n",
    "            y2 = min(image_height, y2)\n",
    "            \n",
    "            # Recompute width and height after clipping\n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "            \n",
    "            area = width * height\n",
    "            objects['id'].append(idx)\n",
    "            objects['area'].append(area)\n",
    "            objects['bbox'].append([x1, y1, width, height])\n",
    "            objects['category'].append(category)\n",
    "    return objects\n",
    "\n",
    "def create_dataset_v2(image_folder, annotation_folder):\n",
    "    dataset = []\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
    "    image_files.sort()\n",
    "    \n",
    "    for i, image_file in enumerate(image_files):\n",
    "        # Construct the annotation filename from the image filename\n",
    "        annotation_file = image_file.replace('.jpg', '.txt')\n",
    "        \n",
    "        # Ensure the annotation file exists\n",
    "        if not os.path.exists(os.path.join(annotation_folder, annotation_file)):\n",
    "            print(f\"Annotation for {image_file} not found. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        image = Image.open(image_path)\n",
    "        image_width, image_height = image.size\n",
    "        \n",
    "        annotation_path = os.path.join(annotation_folder, annotation_file)\n",
    "        objects = parse_annotation(annotation_path, image_width, image_height)\n",
    "        \n",
    "        dataset_entry = {\n",
    "            'image_id': i,\n",
    "            'file_name': image_file,\n",
    "            'width': image_width,\n",
    "            'height': image_height,\n",
    "            'objects': objects\n",
    "        }\n",
    "        dataset.append(dataset_entry)\n",
    "    return dataset\n",
    "\n",
    "# Paths to image and annotation folders\n",
    "image_folder = '/Users/roupenminassian/Downloads/Training File/'\n",
    "annotation_folder = '/Users/roupenminassian/Downloads/Annotations File/'\n",
    "\n",
    "dataset_v2 = create_dataset_v2(image_folder, annotation_folder)\n",
    "\n",
    "# Show first dataset entry\n",
    "dataset_v2[0] if dataset_v2 else \"No valid dataset entries found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_to_jsonl_v2(dataset, output_file_path):\n",
    "    \"\"\"\n",
    "    Save the dataset to a JSONL (JSON Lines) file in the new format.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset: List of dataset entries\n",
    "    - output_file_path: Path to the output JSONL file\n",
    "    \"\"\"\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        for entry in dataset:\n",
    "            # Prepare the entry in the desired output format\n",
    "            output_entry = {\n",
    "                'file_name': entry['file_name'],  # Use the actual file name\n",
    "                'image_id': entry['image_id'],\n",
    "                'width': entry['width'],\n",
    "                'height': entry['height'],\n",
    "                'objects': {\n",
    "                    'id': entry['objects']['id'],\n",
    "                    'area': entry['objects']['area'],\n",
    "                    'bbox': entry['objects']['bbox'],\n",
    "                    'category': entry['objects']['category']\n",
    "                }\n",
    "            }\n",
    "            # Write each entry as a JSON object on a new line\n",
    "            f.write(json.dumps(output_entry) + '\\n')\n",
    "\n",
    "# Path to the JSONL file\n",
    "output_file_path = '/Users/roupenminassian/Downloads/Training/metadata.jsonl'\n",
    "save_to_jsonl_v2(dataset_v2, output_file_path)\n",
    "\n",
    "# Verify the first few lines from the generated JSONL file\n",
    "with open(output_file_path, 'r') as f:\n",
    "    sample_lines_v2 = [next(f) for _ in range(min(20, len(dataset_v2)))]\n",
    "\n",
    "sample_lines_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def copy_annotated_images(jsonl_path, src_folder, dest_folder):\n",
    "    # Ensure the destination folder exists\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "    \n",
    "    # Open the jsonl file and iterate through each line\n",
    "    with open(jsonl_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            file_name = data['file_name']\n",
    "            src_path = os.path.join(src_folder, file_name)\n",
    "            dest_path = os.path.join(dest_folder, file_name)\n",
    "            \n",
    "            # Check if the file exists in the source folder\n",
    "            if os.path.exists(src_path):\n",
    "                # Copy the file to the destination folder\n",
    "                shutil.copy2(src_path, dest_path)\n",
    "\n",
    "# Path to the jsonl file\n",
    "jsonl_path = '/Users/roupenminassian/Downloads/Training/metadata.jsonl'\n",
    "# Source folder containing the images\n",
    "src_folder = '/Users/roupenminassian/Downloads/Training/Training File/'\n",
    "# Destination folder where the images will be copied\n",
    "dest_folder = '/Users/roupenminassian/Downloads/Training/Train/'\n",
    "\n",
    "# Call the function\n",
    "copy_annotated_images(jsonl_path, src_folder, dest_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "folderPath = \"/Users/roupenminassian/Downloads/Training\"\n",
    "\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=folderPath)\n",
    "dataset.push_to_hub(\"roupenminassian/vehicle-dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
